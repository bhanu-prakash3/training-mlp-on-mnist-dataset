# training-mlp-on-mnist-dataset
### Batch Normalization - BN
### Sigmoid - Sig
### DropOut - DO
## MLP Architecture
#### Input(784)-Sig(630)-BN-DO-Sig(510)-BN-DO-Sig(390)-BN-DO-Sig(510)-BN-DO-Sig(210)-BN-DO-Sig(110)-BN-DO-Softmax(10)->Output   
### Plotting -> Train Loss vs Validation Loss
